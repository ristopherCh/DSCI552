{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import LinearSVC\n",
    "import math\n",
    "import statistics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_roc_curve, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>2. Active Learning Using Support Vector Machines </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. (a) Download the banknote authentication data set. Choose 472 data points randomly as the test set and the remaining 900 points as the training set. This is a binary classification problem.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data\\data_banknote_authentication.txt', header = None)\n",
    "target = df.iloc[:,4]\n",
    "df = df.drop(columns = 4)\n",
    "traindf, testdf, traintarget, testtarget = train_test_split(df, target, test_size = 0.3440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. (b) Repeat each of the following two procedures 50 times, giving 50 errors for 90 SVMs per each procedure.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. (b) i. Train a SVM with a pool of 10 randomly selected data points from the training set using linear kernel and L1 penalty. Select the penalty parameter using 5 fold cross validation (see note on parameters). Repeat this process by adding 10 other randomly selected data points to the pool, until all 900 points are used. Do NOT replace the samples back into the training set at each step. Calculate the test error for each SVM. This will give 90 SVMs that were trained using 10, 20, 30, ... 900 data points and their 90 test errors. This is passive learning.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cgrid = []\n",
    "a = np.arange(-6,9, dtype=float)\n",
    "for i in a:\n",
    "    b = 10**i\n",
    "    Cgrid.append(b)\n",
    "Lparameters = {'C' : Cgrid}\n",
    "\n",
    "traindf2 = traindf\n",
    "traintarget2 = traintarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletraindf = traindf2.sample(10)\n",
    "sampletraintarget = traintarget2.loc[sampletraindf.index]\n",
    "\n",
    "traindf2 = traindf2.drop(index = sampletraindf.index)\n",
    "traintarget2 = traintarget2.drop(index = sampletraintarget.index)\n",
    "\n",
    "svm2 = LinearSVC(penalty = 'l1', dual = False, max_iter = 100000)\n",
    "svm2.fit(sampletraindf, sampletraintarget)\n",
    "\n",
    "gridsearch = GridSearchCV(svm2, param_grid = Lparameters, n_jobs = -1, cv=5)\n",
    "gridsearch.fit(sampletraindf, sampletraintarget)\n",
    "bestsvm = gridsearch.best_estimator_\n",
    "\n",
    "testerror = bestsvm.score(testdf, testtarget)\n",
    "testerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(dual=False, max_iter=100000, penalty='l1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chans\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177966101694916"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. (b) ii. Train a SVM with a pool of 10 randomly selected data points from the training set using linear kernel and L1 penalty (see note on selection). Select the parameters of the SVM with 5 fold cross validation. Choose the 10 closest data points in the training set to the hyperplane of the SVM and add them to the pool. Do not replace the samples back into the training set. Train a new SVM using the pool. Repeat this process until all training data is used. This will give 90 SVMs that were trained using 10, 20, 30, ... 900 data points and their 90 test errors. This is active learning.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. (c) Average the 50 test errors for each of the incrementally trained 90 SVMs in parts ii and iii. This is effectively a Monte-Carlo simulation. Plot average test error versus number of training instances for both active and passive leaners on the same figure and report conclusions. Here, a learning curve is obtained by Monte-Carlo simulation.__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
