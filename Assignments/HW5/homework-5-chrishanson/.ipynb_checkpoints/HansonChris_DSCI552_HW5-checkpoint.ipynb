{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVC\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>1. Multi-class and Multi-Label Classification Using Support Vector Machines </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. (a) Download the ANURAN Calls (MFCCs) Data Set. Choose 70% of the data randomly as the training set.__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('Data\\Anuran Calls (MFCCs)\\Frogs_MFCCs.csv')\n",
    "Targets = df[[\"Family\", \"Genus\", \"Species\"]]\n",
    "df1 = df.drop(['Family', 'Genus', 'Species', 'RecordID'], axis=1)\n",
    "TrainDF, TestDF, TrainTargets, TestTargets = train_test_split(df1, Targets, test_size=0.3, random_state=8)\n",
    "TrainTarget1 = TrainTargets.loc[:, 'Family']\n",
    "TrainTarget2 = TrainTargets.loc[:, 'Genus']\n",
    "TrainTarget3 = TrainTargets.loc[:, 'Species']\n",
    "TestTarget1 = TestTargets.loc[:, 'Family']\n",
    "TestTarget2 = TestTargets.loc[:, 'Genus']\n",
    "TestTarget3 = TestTargets.loc[:, 'Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. (b) Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes. We wish to solve a multi-class and multi-label problem. One of the most important approaches to multi-label classification is to train a classifier for each label (binary relevance). We first try this approach:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. (b) i. Research exact match and hamming score/loss methods for evaluating multi-label classification and use them in evaluating the classifiers in this problem.__  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exact match: The percentage of samples that have all their labels classified correctly.\n",
    "\n",
    "Hamming loss: The fraction of labels that are incorrectly predicted, i.e., the fraction of the wrong labels to the total number of labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. (b) ii. Train a SVM for each of the labels, using Gaussian kernels and one verses all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation. Consider solving the problem with both standardized and raw attributes and reporting the results.__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating my C and Gamma values to be used in cross-validation to find optimum parameters\n",
    "a = np.arange(-3,6, dtype=float)\n",
    "Clogs3 = []\n",
    "for i in a:\n",
    "    b = 10**i\n",
    "    Clogs3.append(b)\n",
    "Clogs2 = [x * 5 for x in Clogs3]\n",
    "Cgrid = Clogs2 + Clogs3\n",
    "b = np.arange(0.001, 1, 0.1)\n",
    "c = np.arange(0,110,10)\n",
    "Ggrid = np.concatenate((b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SVM for Target 1\n",
    "svc1 = SVC(C = 50, kernel='rbf', gamma=0.901, decision_function_shape = 'ovr')\n",
    "#svc1.fit(TrainDF, TrainTarget1)\n",
    "#TestSVCPred1 = svc1.predict(TestDF)\n",
    "#print(classification_report(TestTarget1, TestSVCPred1),)\n",
    "#print(confusion_matrix(TestTarget1, TestSVCPred1))\n",
    "#svc1.score(TestDF, TestTarget1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I've \"muted\" these bits of cross validation code because I've already gotten the output from them that I want and they take a long time to run. They are still functional if you remove the #'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C and gamma parameters for Target 1\n",
    "#parameters = {'C': Cgrid, 'gamma': Ggrid}\n",
    "#GSSVM1 = GridSearchCV(svc1, param_grid=parameters, n_jobs=-1, cv=10)\n",
    "#GSSVM1.fit(TrainDF, TrainTarget1)\n",
    "#GSSVM1.best_estimator_\n",
    "#Result: C=50.0, gamma=0.901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C and gamma parameters for Target 2\n",
    "#GSSVM2 = GridSearchCV(svc1, param_grid=parameters, n_jobs=-1, cv=10)\n",
    "#GSSVM2.fit(TrainDF, TrainTarget2)\n",
    "#GSSVM2.best_estimator_\n",
    "#Result: C=500.0, gamma=0.901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C and gamma parameters for Target 3\n",
    "#GSSVM3 = GridSearchCV(svc1, param_grid=parameters, n_jobs=-1, cv=10)\n",
    "#GSSVM3.fit(TrainDF, TrainTarget3)\n",
    "#GSSVM3.best_estimator_\n",
    "#Result: C=10.0, gamma=0.901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Bufonidae       1.00      1.00      1.00        16\n",
      "  Dendrobatidae       0.99      0.99      0.99       163\n",
      "        Hylidae       0.99      0.99      0.99       641\n",
      "Leptodactylidae       1.00      1.00      1.00      1339\n",
      "\n",
      "       accuracy                           0.99      2159\n",
      "      macro avg       0.99      1.00      0.99      2159\n",
      "   weighted avg       0.99      0.99      0.99      2159\n",
      "\n",
      "[[  16    0    0    0]\n",
      " [   0  162    1    0]\n",
      " [   0    1  635    5]\n",
      " [   0    1    5 1333]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9939786938397406"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final SVM for Target 1\n",
    "svc2 = SVC(C = 50, kernel='rbf', gamma=0.901, decision_function_shape = 'ovr')\n",
    "svc2.fit(TrainDF, TrainTarget1)\n",
    "TestSVCPred1 = svc2.predict(TestDF)\n",
    "print(classification_report(TestTarget1, TestSVCPred1),)\n",
    "print(confusion_matrix(TestTarget1, TestSVCPred1))\n",
    "svc2.score(TestDF, TestTarget1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Adenomera       1.00      1.00      1.00      1261\n",
      "     Ameerega       0.99      0.99      0.99       163\n",
      "Dendropsophus       0.97      0.97      0.97        86\n",
      "    Hypsiboas       0.99      0.99      0.99       485\n",
      "Leptodactylus       0.96      1.00      0.98        78\n",
      "Osteocephalus       0.91      0.89      0.90        35\n",
      "     Rhinella       1.00      1.00      1.00        16\n",
      "       Scinax       0.97      0.97      0.97        35\n",
      "\n",
      "     accuracy                           0.99      2159\n",
      "    macro avg       0.97      0.97      0.97      2159\n",
      " weighted avg       0.99      0.99      0.99      2159\n",
      "\n",
      "[[1256    1    1    1    0    1    0    1]\n",
      " [   0  162    1    0    0    0    0    0]\n",
      " [   3    0   83    0    0    0    0    0]\n",
      " [   1    0    0  479    3    2    0    0]\n",
      " [   0    0    0    0   78    0    0    0]\n",
      " [   2    0    0    2    0   31    0    0]\n",
      " [   0    0    0    0    0    0   16    0]\n",
      " [   0    0    1    0    0    0    0   34]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9907364520611394"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final SVM for Target 2\n",
    "svc3 = SVC(C = 500, kernel='rbf', gamma=0.901, decision_function_shape = 'ovr')\n",
    "svc3.fit(TrainDF, TrainTarget2)\n",
    "TestSVCPred2 = svc3.predict(TestDF)\n",
    "print(classification_report(TestTarget2, TestSVCPred2),)\n",
    "print(confusion_matrix(TestTarget2, TestSVCPred2))\n",
    "svc3.score(TestDF, TestTarget2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.98      0.97      0.98       200\n",
      "AdenomeraHylaedactylus       1.00      1.00      1.00      1061\n",
      "    Ameeregatrivittata       0.99      0.99      0.99       163\n",
      "            HylaMinuta       0.94      0.98      0.96        86\n",
      "  HypsiboasCinerascens       0.99      0.98      0.99       131\n",
      "     HypsiboasCordobae       1.00      0.99      1.00       354\n",
      "   LeptodactylusFuscus       1.00      1.00      1.00        78\n",
      " OsteocephalusOophagus       0.92      0.94      0.93        35\n",
      "     Rhinellagranulosa       1.00      1.00      1.00        16\n",
      "           ScinaxRuber       0.97      0.97      0.97        35\n",
      "\n",
      "              accuracy                           0.99      2159\n",
      "             macro avg       0.98      0.98      0.98      2159\n",
      "          weighted avg       0.99      0.99      0.99      2159\n",
      "\n",
      "[[ 195    0    1    2    0    0    0    1    0    1]\n",
      " [   0 1059    0    1    0    1    0    0    0    0]\n",
      " [   0    0  161    2    0    0    0    0    0    0]\n",
      " [   1    1    0   84    0    0    0    0    0    0]\n",
      " [   1    0    0    0  129    0    0    1    0    0]\n",
      " [   0    0    0    0    1  352    0    1    0    0]\n",
      " [   0    0    0    0    0    0   78    0    0    0]\n",
      " [   2    0    0    0    0    0    0   33    0    0]\n",
      " [   0    0    0    0    0    0    0    0   16    0]\n",
      " [   0    1    0    0    0    0    0    0    0   34]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9916628068550255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final SVM for Target 3\n",
    "svc4 = SVC(C = 10, kernel='rbf', gamma=0.901, decision_function_shape = 'ovr')\n",
    "svc4.fit(TrainDF, TrainTarget3)\n",
    "TestSVCPred3 = svc4.predict(TestDF)\n",
    "print(classification_report(TestTarget3, TestSVCPred3),)\n",
    "print(confusion_matrix(TestTarget3, TestSVCPred3))\n",
    "svc4.score(TestDF, TestTarget3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSVCPred1DF = pd.DataFrame(data=TestSVCPred1)\n",
    "TestSVCPred2DF = pd.DataFrame(data=TestSVCPred2)\n",
    "TestSVCPred3DF = pd.DataFrame(data=TestSVCPred3)\n",
    "TestSVCPredDF = pd.concat([TestSVCPred1DF,TestSVCPred2DF,TestSVCPred3DF], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestTargets2 = TestTargets.reset_index(drop=True)\n",
    "TestTargets2.columns = range(TestTargets2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007874015748031496\n"
     ]
    }
   ],
   "source": [
    "#Hamming Loss for SVM\n",
    "from sklearn.metrics import hamming_loss\n",
    "HL1 = hamming_loss(TestTarget1, TestSVCPred1)\n",
    "HL2 = hamming_loss(TestTarget2, TestSVCPred2)\n",
    "HL3 = hamming_loss(TestTarget3, TestSVCPred3)\n",
    "SVCHL = (HL1 + HL2 + HL3)/3\n",
    "print(SVCHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921259842519685"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hamming Score\n",
    "1-SVCHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of misclassified labels\n",
    "(HL1*2159) + (HL2*2159) + (HL3*2159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861046780917091"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exact Match for SVC\n",
    "ExactMatch1 = TestTargets2.compare(TestSVCPredDF)\n",
    "(len(TestTargets2)-len(ExactMatch1))/len(TestTargets2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. (b) iii. Repeat 1(b)ii with L1-penalized (with linear kernel) SVMs. Remember to standardize the attributes. Determine the weight of the SVM penalty using 10 fold cross validation.__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the attributes (mean zero, STD 1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "TrainScaled = scaler.fit_transform(TrainDF)\n",
    "\n",
    "#Scale test data using scaler fit to training data\n",
    "TestScaled = scaler.transform(TestDF)\n",
    "TestDFscaled = pd.DataFrame(data=TestScaled)\n",
    "TrainDFscaled = pd.DataFrame(data=TrainScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lparameters = {'C': Cgrid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Bufonidae       0.00      0.00      0.00        16\n",
      "  Dendrobatidae       0.88      0.86      0.87       163\n",
      "        Hylidae       0.90      0.91      0.90       641\n",
      "Leptodactylidae       0.96      0.97      0.97      1339\n",
      "\n",
      "       accuracy                           0.94      2159\n",
      "      macro avg       0.68      0.68      0.68      2159\n",
      "   weighted avg       0.93      0.94      0.93      2159\n",
      "\n",
      "[[   0    0   16    0]\n",
      " [   0  140   19    4]\n",
      " [   1   12  581   47]\n",
      " [   0    8   29 1302]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.937007874015748"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repeat ii with L1-penalized SVMs with linear kernel. \n",
    "from sklearn.svm import LinearSVC\n",
    "lsvc1 = LinearSVC(penalty = 'l1', C=0.5, dual=False, max_iter=5000)\n",
    "lsvc1.fit(TrainDFscaled, TrainTarget1)\n",
    "TestLSVCPred1 = lsvc1.predict(TestDFscaled)\n",
    "print(classification_report(TestTarget1, TestLSVCPred1))\n",
    "print(confusion_matrix(TestTarget1, TestLSVCPred1))\n",
    "lsvc1.score(TestDFscaled, TestTarget1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Adenomera       0.97      0.99      0.98      1261\n",
      "     Ameerega       0.90      0.93      0.92       163\n",
      "Dendropsophus       0.94      0.67      0.78        86\n",
      "    Hypsiboas       0.94      0.97      0.95       485\n",
      "Leptodactylus       0.96      0.94      0.95        78\n",
      "Osteocephalus       0.82      0.51      0.63        35\n",
      "     Rhinella       0.93      0.81      0.87        16\n",
      "       Scinax       0.97      1.00      0.99        35\n",
      "\n",
      "     accuracy                           0.96      2159\n",
      "    macro avg       0.93      0.85      0.88      2159\n",
      " weighted avg       0.96      0.96      0.95      2159\n",
      "\n",
      "[[1245    7    0    6    0    2    0    1]\n",
      " [   5  152    4    2    0    0    0    0]\n",
      " [  16    8   58    4    0    0    0    0]\n",
      " [   9    0    0  472    3    1    0    0]\n",
      " [   0    0    0    4   73    1    0    0]\n",
      " [   1    1    0   14    0   18    1    0]\n",
      " [   1    0    0    2    0    0   13    0]\n",
      " [   0    0    0    0    0    0    0   35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9569245020842982"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVM for Target 2\n",
    "lsvc2 = LinearSVC(penalty = 'l1', C=10, dual=False, max_iter=5000)\n",
    "lsvc2.fit(TrainDFscaled, TrainTarget2)\n",
    "TestLSVCPred2 = lsvc2.predict(TestDFscaled)\n",
    "print(classification_report(TestTarget2, TestLSVCPred2))\n",
    "print(confusion_matrix(TestTarget2, TestLSVCPred2))\n",
    "lsvc2.score(TestDFscaled, TestTarget2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.92      0.93      0.92       200\n",
      "AdenomeraHylaedactylus       0.99      1.00      1.00      1061\n",
      "    Ameeregatrivittata       0.89      0.93      0.91       163\n",
      "            HylaMinuta       0.90      0.73      0.81        86\n",
      "  HypsiboasCinerascens       0.95      0.93      0.94       131\n",
      "     HypsiboasCordobae       0.93      0.97      0.95       354\n",
      "   LeptodactylusFuscus       0.97      0.95      0.96        78\n",
      " OsteocephalusOophagus       0.91      0.57      0.70        35\n",
      "     Rhinellagranulosa       0.84      1.00      0.91        16\n",
      "           ScinaxRuber       0.97      1.00      0.99        35\n",
      "\n",
      "              accuracy                           0.96      2159\n",
      "             macro avg       0.93      0.90      0.91      2159\n",
      "          weighted avg       0.96      0.96      0.96      2159\n",
      "\n",
      "[[ 185    0    7    2    0    4    0    1    0    1]\n",
      " [   0 1060    0    0    0    1    0    0    0    0]\n",
      " [   3    0  151    5    0    3    0    0    1    0]\n",
      " [   7    3   10   63    1    2    0    0    0    0]\n",
      " [   3    0    1    0  122    4    1    0    0    0]\n",
      " [   0    3    0    0    4  345    1    1    0    0]\n",
      " [   1    0    0    0    0    3   74    0    0    0]\n",
      " [   2    0    0    0    1   10    0   20    2    0]\n",
      " [   0    0    0    0    0    0    0    0   16    0]\n",
      " [   0    0    0    0    0    0    0    0    0   35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9592403890690134"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVM for Target 3\n",
    "lsvc3 = LinearSVC(penalty = 'l1', C=5, dual=False, max_iter=5000)\n",
    "lsvc3.fit(TrainDFscaled, TrainTarget3)\n",
    "TestLSVCPred3 = lsvc3.predict(TestDFscaled)\n",
    "print(classification_report(TestTarget3, TestLSVCPred3, zero_division=1))\n",
    "print(confusion_matrix(TestTarget3, TestLSVCPred3))\n",
    "lsvc3.score(TestDFscaled, TestTarget3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C for Target 1 using LinearSVM\n",
    "#GSLSVM1 = GridSearchCV(lsvc1, param_grid=Lparameters, n_jobs=-1, cv=10)\n",
    "#GSLSVM1.fit(TrainDFscaled, TrainTarget1)\n",
    "#GSLSVM1.best_estimator_\n",
    "#Result: C=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C for Target 2 using LinearSVM\n",
    "#GSLSVM2 = GridSearchCV(lsvc2, param_grid=Lparameters, n_jobs=-1, cv=10)\n",
    "#GSLSVM2.fit(TrainDFscaled, TrainTarget2)\n",
    "#GSLSVM2.best_estimator_\n",
    "#Result: C=10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C for Target 2 using LinearSVM.\n",
    "#GSLSVM3 = GridSearchCV(lsvc3, param_grid=Lparameters, n_jobs=-1, cv=10)\n",
    "#GSLSVM3.fit(TrainDFscaled, TrainTarget3)\n",
    "#GSLSVM3.best_estimator_\n",
    "#Result: C=5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestLSVCPred1DF = pd.DataFrame(data=TestLSVCPred1)\n",
    "TestLSVCPred2DF = pd.DataFrame(data=TestLSVCPred2)\n",
    "TestLSVCPred3DF = pd.DataFrame(data=TestLSVCPred3)\n",
    "TestLSVCPredDF = pd.concat([TestLSVCPred1DF,TestLSVCPred2DF,TestLSVCPred3DF], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04894241161031341\n"
     ]
    }
   ],
   "source": [
    "#Hamming Loss for LSVM\n",
    "LHL1 = hamming_loss(TestTarget1, TestLSVCPred1)\n",
    "LHL2 = hamming_loss(TestTarget2, TestLSVCPred2)\n",
    "LHL3 = hamming_loss(TestTarget3, TestLSVCPred3)\n",
    "LSVCHL = (LHL1 + LHL2 + LHL3)/3\n",
    "print(LSVCHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9510575883896866"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hamming score\n",
    "1-LSVCHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of misclassified labels\n",
    "(LHL1*2159) + (LHL2*2159) + (LHL3*2159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.920796665122742"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exact Match for LSVC\n",
    "ExactMatch2 = TestTargets2.compare(TestLSVCPredDF)\n",
    "(len(TestTargets2)-len(ExactMatch2))/len(TestTargets2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. (b) iv. Repeat 1(b)iii by using SMOTE or any other method to remedy class imbalance. Report conclusions about the classifiers trained.__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE my training data\n",
    "sm1 = SMOTE()\n",
    "TrainDFscaled1SM, TrainTarget1SM = sm1.fit_resample(TrainDFscaled, TrainTarget1)\n",
    "TrainDFscaled2SM, TrainTarget2SM = sm1.fit_resample(TrainDFscaled, TrainTarget2)\n",
    "TrainDFscaled3SM, TrainTarget3SM = sm1.fit_resample(TrainDFscaled, TrainTarget3)\n",
    "\n",
    "#TrainTarget1SM = pd.DataFrame(data=TrainTarget1SM)\n",
    "#TrainTarget2SM = pd.DataFrame(data=TrainTarget2SM)\n",
    "#TrainTarget3SM = pd.DataFrame(data=TrainTarget3SM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Bufonidae       0.25      1.00      0.41        16\n",
      "  Dendrobatidae       0.76      0.95      0.84       163\n",
      "        Hylidae       0.93      0.88      0.90       641\n",
      "Leptodactylidae       0.98      0.94      0.96      1339\n",
      "\n",
      "       accuracy                           0.92      2159\n",
      "      macro avg       0.73      0.94      0.78      2159\n",
      "   weighted avg       0.94      0.92      0.93      2159\n",
      "\n",
      "[[  16    0    0    0]\n",
      " [   1  155    5    2]\n",
      " [  19   34  563   25]\n",
      " [  27   16   39 1257]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9221861973135711"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repeat iii with SMOTE performed to correct class imbalance. \n",
    "#Linear SVC for SMOTE target 1\n",
    "SMsvc1 = LinearSVC(penalty = 'l1', C=5, dual=False, max_iter=10000)\n",
    "SMsvc1.fit(TrainDFscaled1SM, TrainTarget1SM)\n",
    "TestSMSVCPred1 = SMsvc1.predict(TestDFscaled)\n",
    "print(classification_report(TestTarget1, TestSMSVCPred1))\n",
    "print(confusion_matrix(TestTarget1, TestSMSVCPred1))\n",
    "SMsvc1.score(TestDFscaled, TestTarget1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Adenomera       0.99      0.92      0.95      1261\n",
      "     Ameerega       0.87      0.94      0.91       163\n",
      "Dendropsophus       0.67      0.84      0.74        86\n",
      "    Hypsiboas       0.97      0.92      0.94       485\n",
      "Leptodactylus       0.89      0.95      0.92        78\n",
      "Osteocephalus       0.46      0.89      0.61        35\n",
      "     Rhinella       0.30      1.00      0.46        16\n",
      "       Scinax       0.85      1.00      0.92        35\n",
      "\n",
      "     accuracy                           0.92      2159\n",
      "    macro avg       0.75      0.93      0.81      2159\n",
      " weighted avg       0.94      0.92      0.93      2159\n",
      "\n",
      "[[1160   16   30    9    0   21   24    1]\n",
      " [   2  154    6    0    0    0    1    0]\n",
      " [   2    7   72    1    1    0    3    0]\n",
      " [   7    0    0  445    8   14    6    5]\n",
      " [   0    0    0    2   74    1    1    0]\n",
      " [   0    0    0    2    0   31    2    0]\n",
      " [   0    0    0    0    0    0   16    0]\n",
      " [   0    0    0    0    0    0    0   35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9203334877257989"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVC for SMOTE target 2\n",
    "SMsvc2 = LinearSVC(penalty = 'l1', C=50, dual=False, max_iter=10000)\n",
    "SMsvc2.fit(TrainDFscaled2SM, TrainTarget2SM)\n",
    "TestSMSVCPred2 = SMsvc2.predict(TestDFscaled)\n",
    "print(classification_report(TestTarget2, TestSMSVCPred2))\n",
    "print(confusion_matrix(TestTarget2, TestSMSVCPred2))\n",
    "SMsvc2.score(TestDFscaled, TestTarget2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.96      0.91      0.93       200\n",
      "AdenomeraHylaedactylus       1.00      0.99      1.00      1061\n",
      "    Ameeregatrivittata       0.89      0.90      0.89       163\n",
      "            HylaMinuta       0.82      0.79      0.80        86\n",
      "  HypsiboasCinerascens       0.91      0.90      0.91       131\n",
      "     HypsiboasCordobae       0.95      0.94      0.95       354\n",
      "   LeptodactylusFuscus       0.91      0.94      0.92        78\n",
      " OsteocephalusOophagus       0.74      0.80      0.77        35\n",
      "     Rhinellagranulosa       0.48      1.00      0.65        16\n",
      "           ScinaxRuber       0.95      1.00      0.97        35\n",
      "\n",
      "              accuracy                           0.95      2159\n",
      "             macro avg       0.86      0.92      0.88      2159\n",
      "          weighted avg       0.95      0.95      0.95      2159\n",
      "\n",
      "[[ 181    0    9    3    0    1    0    3    2    1]\n",
      " [   0 1054    0    2    3    2    0    0    0    0]\n",
      " [   2    0  146    9    0    3    0    0    2    1]\n",
      " [   4    1    9   68    0    0    1    0    3    0]\n",
      " [   1    0    0    0  118    4    3    3    2    0]\n",
      " [   0    2    0    0    8  333    3    3    5    0]\n",
      " [   0    0    0    1    0    2   73    1    1    0]\n",
      " [   1    0    0    0    0    4    0   28    2    0]\n",
      " [   0    0    0    0    0    0    0    0   16    0]\n",
      " [   0    0    0    0    0    0    0    0    0   35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9504400185270959"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVC for SMOTE target 3\n",
    "SMsvc3 = LinearSVC(penalty = 'l1', C=50, dual=False, max_iter=25000)\n",
    "SMsvc3.fit(TrainDFscaled3SM, TrainTarget3SM)\n",
    "TestSMSVCPred3 = SMsvc3.predict(TestDFscaled)\n",
    "print(classification_report(TestTarget3, TestSMSVCPred3))\n",
    "print(confusion_matrix(TestTarget3, TestSMSVCPred3))\n",
    "SMsvc3.score(TestDFscaled, TestTarget3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C for Target 1 using LinearSVM and a 'SMOTE'-ed dataset\n",
    "#GSSMSVM1 = GridSearchCV(SMsvc1, param_grid=Lparameters, n_jobs=-1, cv=10)\n",
    "#GSSMSVM1.fit(TrainDFscaled1SM, TrainTarget1SM)\n",
    "#GSSMSVM1.best_estimator_\n",
    "#Result: C=5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C for Target 2 using LinearSVM and a 'SMOTE'-ed dataset\n",
    "#GSSMSVM2 = GridSearchCV(SMsvc2, param_grid=Lparameters, n_jobs=-1, cv=10)\n",
    "#GSSMSVM2.fit(TrainDFscaled2SM, TrainTarget2SM)\n",
    "#GSSMSVM2.best_estimator_\n",
    "#Result: C=50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to find best C for Target 3 using LinearSVM and a 'SMOTE'-ed dataset\n",
    "#GSSMSVM3 = GridSearchCV(SMsvc3, param_grid=Lparameters, n_jobs=-1, cv=10)\n",
    "#GSSMSVM3.fit(TrainDFscaled3SM, TrainTarget3SM)\n",
    "#GSSMSVM3.best_estimator_\n",
    "#Result: C=50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSMSVCPred1DF = pd.DataFrame(data=TestSMSVCPred1)\n",
    "TestSMSVCPred2DF = pd.DataFrame(data=TestSMSVCPred2)\n",
    "TestSMSVCPred3DF = pd.DataFrame(data=TestSMSVCPred3)\n",
    "TestSMSVCPredDF = pd.concat([TestSMSVCPred1DF,TestSMSVCPred2DF,TestSMSVCPred3DF], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06901343214451135\n"
     ]
    }
   ],
   "source": [
    "#Hamming Loss for SMOTE-LSVM\n",
    "SMHL1 = hamming_loss(TestTarget1, TestSMSVCPred1)\n",
    "SMHL2 = hamming_loss(TestTarget2, TestSMSVCPred2)\n",
    "SMHL3 = hamming_loss(TestTarget3, TestSMSVCPred3)\n",
    "SMSVCHL = (SMHL1 + SMHL2 + SMHL3)/3\n",
    "print(SMSVCHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9309865678554886"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hamming score for SMOTE-LSVM\n",
    "1-SMSVCHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of misclassified labels\n",
    "(SMHL1*2159) + (SMHL2*2159)+ (SMHL3*2159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693839740620658"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exact Match for SMOTE-LSVM\n",
    "ExactMatch3 = TestTargets2.compare(TestSMSVCPredDF)\n",
    "(len(TestTargets2)-len(ExactMatch3))/len(TestTargets2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most accurate classifier was the SVM with Gaussian kernels. It had much better classification of both under and over represented classes than did any other method.\n",
    "\n",
    "SMOTE decreased total accuracy of the classifier but increased the precision of classification for under-represented classes. For example, the score of the classification was 0.937 without SMOTE but only 0.926 with it, however, without SMOTE the classifier mis-classified all 16 of the under-represented \"Bufonidae\" class, while with SMOTE it correctly identified all 16 \"Bufonidae.\" This is a critical improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>2. K-Means Clustering on a Multi-Class and Multi-Label Data Set </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Monte-Carlo Simulation: Perform the following procedures 50 times and report the average and standard deviation of the 50 Hamming Distances that are calculated__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. (a) Use k-means clustering on the whole Anuran Calls (MFCCs) Data Set (do not split the data into train and test, as we are not performing supervised learning in this exercise). Choose k in {1, 2, ..., 50} automatically based on one of the methods provided in the slides (CH or Gap Statistics or scree plots or Silhouettes) or any other method known.__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "WholeDF = df1\n",
    "Target1 = Targets.iloc[:,0]\n",
    "Target2 = Targets.iloc[:,1]\n",
    "Target3 = Targets.iloc[:,2]\n",
    "WholeDFscaled = scaler.fit_transform(WholeDF)\n",
    "WholeDFscaled = pd.DataFrame(data=WholeDFscaled)\n",
    "Target1 = pd.DataFrame(data=Target1)\n",
    "Target2 = pd.DataFrame(data=Target2)\n",
    "Target3 = pd.DataFrame(data=Target3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMHL50 = []\n",
    "KMHS50 = []\n",
    "\n",
    "for j in range(0,50): \n",
    "\n",
    "    KCH = []\n",
    "    KS = []\n",
    "    for i in range(2,52):\n",
    "        kmeans = KMeans(n_clusters = i, init = 'random').fit(WholeDF)\n",
    "        kmlabels = kmeans.labels_\n",
    "        #chs = calinski_harabasz_score(WholeDF, kmlabels)\n",
    "        ss = silhouette_score(WholeDF, kmlabels)\n",
    "        #KCH.append(chs)\n",
    "        KS.append(ss)\n",
    "    \n",
    "    SMAX = np.argmax(KS) + 2 #this is the ideal k value\n",
    "\n",
    "    kmeans4 = KMeans(n_clusters = SMAX).fit(WholeDF) #re-cluster with ideal K from above\n",
    "    km4labels = kmeans4.labels_\n",
    "    km4labels = pd.DataFrame(data=km4labels, columns = ['Cluster'])\n",
    "\n",
    "    T1C = pd.concat([km4labels, Target1], axis=1) #assign true labels to clusters\n",
    "    cluster01 = T1C[T1C[\"Cluster\"] == 0]\n",
    "    cluster11 = T1C[T1C[\"Cluster\"] == 1]\n",
    "    cluster21 = T1C[T1C[\"Cluster\"] == 2]\n",
    "    cluster31 = T1C[T1C[\"Cluster\"] == 3]\n",
    "\n",
    "    T2C = pd.concat([km4labels, Target2], axis=1)\n",
    "    cluster02 = T2C[T2C[\"Cluster\"] == 0]\n",
    "    cluster12 = T2C[T2C[\"Cluster\"] == 1]\n",
    "    cluster22 = T2C[T2C[\"Cluster\"] == 2]\n",
    "    cluster32 = T2C[T2C[\"Cluster\"] == 3]\n",
    "\n",
    "    T3C = pd.concat([km4labels, Target3], axis=1)\n",
    "    cluster03 = T3C[T3C[\"Cluster\"] == 0]\n",
    "    cluster13 = T3C[T3C[\"Cluster\"] == 1]\n",
    "    cluster23 = T3C[T3C[\"Cluster\"] == 2]\n",
    "    cluster33 = T3C[T3C[\"Cluster\"] == 3]\n",
    "\n",
    "    #create a DF in which the cluster predicted family genus species are aligned with their DF sample\n",
    "    allcluster0 = pd.concat([cluster01, cluster02[\"Genus\"], cluster03[\"Species\"]], axis=1)\n",
    "    allcluster1 = pd.concat([cluster11, cluster12[\"Genus\"], cluster13[\"Species\"]], axis=1)\n",
    "    allcluster2 = pd.concat([cluster21, cluster22[\"Genus\"], cluster23[\"Species\"]], axis=1)\n",
    "    allcluster3 = pd.concat([cluster31, cluster32[\"Genus\"], cluster33[\"Species\"]], axis=1)\n",
    "    allcluster = pd.concat([allcluster0, allcluster1, allcluster2, allcluster3]).sort_index()\n",
    "    \n",
    "    mode0 = allcluster0.mode()\n",
    "    Fam0Mode = mode0.iloc[0,1]\n",
    "    Gen0Mode = mode0.iloc[0,2]\n",
    "    Spe0Mode = mode0.iloc[0,3]\n",
    "    mode1 = allcluster1.mode()\n",
    "    Fam1Mode = mode1.iloc[0,1]\n",
    "    Gen1Mode = mode1.iloc[0,2]\n",
    "    Spe1Mode = mode1.iloc[0,3]\n",
    "    mode2 = allcluster0.mode()\n",
    "    Fam2Mode = mode2.iloc[0,1]\n",
    "    Gen2Mode = mode2.iloc[0,2]\n",
    "    Spe2Mode = mode2.iloc[0,3]\n",
    "    mode3 = allcluster0.mode()\n",
    "    Fam3Mode = mode3.iloc[0,1]\n",
    "    Gen3Mode = mode3.iloc[0,2]\n",
    "    Spe3Mode = mode3.iloc[0,3]\n",
    "    newallcluster0 = allcluster0.drop(columns = ['Family', 'Genus', 'Species'])\n",
    "    newallcluster0['Family'] = Fam0Mode\n",
    "    newallcluster0['Genus'] = Gen0Mode\n",
    "    newallcluster0['Species'] = Spe0Mode\n",
    "    newallcluster1 = allcluster1.drop(columns = ['Family', 'Genus', 'Species'])\n",
    "    newallcluster1['Family'] = Fam1Mode\n",
    "    newallcluster1['Genus'] = Gen1Mode\n",
    "    newallcluster1['Species'] = Spe1Mode\n",
    "    newallcluster2 = allcluster2.drop(columns = ['Family', 'Genus', 'Species'])\n",
    "    newallcluster2['Family'] = Fam2Mode\n",
    "    newallcluster2['Genus'] = Gen2Mode\n",
    "    newallcluster2['Species'] = Spe2Mode\n",
    "    newallcluster3 = allcluster3.drop(columns = ['Family', 'Genus', 'Species'])\n",
    "    newallcluster3['Family'] = Fam3Mode\n",
    "    newallcluster3['Genus'] = Gen3Mode\n",
    "    newallcluster3['Species'] = Spe3Mode\n",
    "    newallcluster = pd.concat([newallcluster0, newallcluster1, newallcluster2, newallcluster3]).sort_index()\n",
    "\n",
    "    KMHL1 = hamming_loss(Target1, newallcluster.iloc[:,1])\n",
    "    KMHL2 = hamming_loss(Target2, newallcluster.iloc[:,2])\n",
    "    KMHL3 = hamming_loss(Target3, newallcluster.iloc[:,3])\n",
    "    KMHL = (KMHL1 + KMHL2 + KMHL3)/3\n",
    "\n",
    "    KMHS = 1-KMHL\n",
    "\n",
    "    KMHL50.append(KMHL)\n",
    "    KMHS50.append(KMHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. (c) For each cluster there is a majority label triplet (family, genus, species). Calculate the average Hamming score and Hamming loss between the true labels and the labels assigned by clusters.__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5570998378503591,\n",
       " 0.6725040537410238,\n",
       " 0.5887421820708825,\n",
       " 0.5570998378503591,\n",
       " 0.5570998378503591,\n",
       " 0.6642575862867732,\n",
       " 0.6725040537410238,\n",
       " 0.7020152883947186,\n",
       " 0.6642575862867732,\n",
       " 0.6643965716933056,\n",
       " 0.6645355570998379,\n",
       " 0.7020152883947186,\n",
       " 0.22242297892054674,\n",
       " 0.6642575862867732,\n",
       " 0.5570998378503591,\n",
       " 0.7020152883947186,\n",
       " 0.599953671531156,\n",
       " 0.5570998378503591,\n",
       " 0.6643965716933056,\n",
       " 0.24220523511697944,\n",
       " 0.6642575862867732,\n",
       " 0.6645355570998379,\n",
       " 0.6725040537410238,\n",
       " 0.6748668056520732,\n",
       " 0.5570998378503591,\n",
       " 0.6642575862867732,\n",
       " 0.7020152883947186,\n",
       " 0.5570998378503591,\n",
       " 0.6725040537410238,\n",
       " 0.599953671531156,\n",
       " 0.6642575862867732,\n",
       " 0.6253880009265693,\n",
       " 0.5570998378503591,\n",
       " 0.5570998378503591,\n",
       " 0.6642575862867732,\n",
       " 0.6642575862867732,\n",
       " 0.5570998378503591,\n",
       " 0.6296965485290711,\n",
       " 0.5570998378503591,\n",
       " 0.5570998378503591,\n",
       " 0.6642575862867732,\n",
       " 0.6642575862867732,\n",
       " 0.6642575862867732,\n",
       " 0.599953671531156,\n",
       " 0.6725040537410238,\n",
       " 0.599953671531156,\n",
       " 0.7020152883947186,\n",
       " 0.5570998378503591,\n",
       " 0.2260365994903868,\n",
       " 0.7006254343293954]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here are the 50 Hamming Scores from performing the procedure 50 times.\n",
    "KMHS50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.607787815612694"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "#Averave Hamming Score\n",
    "statistics.mean(KMHS50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.392212184387306"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average Hamming Loss\n",
    "statistics.mean(KMHL50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10964409407789628"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hamming Loss Standard Deviation\n",
    "statistics.stdev(KMHL50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about above code: I admit, it's not quite right. This works when the K value chosen by Silhouette Score is K=4, which it usually is, but it it will sometimes fail before it gets to 50 iterations. It's good enough that it can get me a lot of data and I can estimate the Hamming scores pretty well, but it would require some re-coding to be perfect, and I only realized this too late."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. ISLR 10.7.2__  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See included PDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
